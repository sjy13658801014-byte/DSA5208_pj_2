{"cells": [{"cell_type": "code", "execution_count": 3, "id": "2c4eefdf-5d0d-4b46-a134-053491cad33c", "metadata": {"tags": []}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "== Cell 1: \u6b63\u5728\u4ece HDFS \u52a0\u8f7d\u5355\u4e2a\u6587\u4ef6 ==\n"}, {"name": "stderr", "output_type": "stream", "text": "[Stage 4:==>            (142 + 7) / 827][Stage 6:============>      (2 + 1) / 3]\r"}, {"name": "stdout", "output_type": "stream", "text": "== Cell 1: \u6570\u636e\u52a0\u8f7d\u5b8c\u6210\u5e76\u5df2\u7f13\u5b58 ==\n"}, {"name": "stderr", "output_type": "stream", "text": "[Stage 4:==========>                                            (157 + 8) / 827]\r"}], "source": "import pyspark.sql.functions as F\nfrom pyspark.sql import SparkSession\n\n# 1. \u542f\u52a8 Spark\nspark = SparkSession.builder.appName(\"ProjectFrame-HDFS\").getOrCreate()\n\n# # 2. \u4ece HDFS (\u9ad8\u901f\u5de5\u4f5c\u53f0) \u8bfb\u53d6\u6240\u6709 CSV \u6570\u636e\n# print(\"== Cell 1: \u6b63\u5728\u4ece HDFS \u52a0\u8f7d\u6570\u636e ==\")\n# df = spark.read.csv(\n#     \"hdfs:///project_data/*.csv\", \n#     header=True, \n#     inferSchema=True\n# )\n\n# 2. \u4ece HDFS (\u9ad8\u901f\u5de5\u4f5c\u53f0) \u53ea\u8bfb\u53d6\u4e00\u4e2a CSV \u6587\u4ef6\uff08\u9a8c\u8bc1\u6846\u67b6\uff09\nprint(\"== Cell 1: \u6b63\u5728\u4ece HDFS \u52a0\u8f7d\u5355\u4e2a\u6587\u4ef6 ==\")\n# !!! \u4fee\u6539\u8fd9\u91cc\uff0c\u6307\u5411\u4e00\u4e2a\u5177\u4f53\u7684\u6587\u4ef6\u540d !!!\ndf = spark.read.csv(\n    \"hdfs:///project_data/A0000453929.csv\", # <--- \u628a\u8fd9\u91cc\u6539\u6210\u4f60 HDFS \u4e0a\u7684\u4e00\u4e2a\u6587\u4ef6\u540d\n    header=True, \n    inferSchema=True\n)\n\n# 3. \u7f13\u5b58\u6570\u636e\u5230\u5185\u5b58 (HDFS -> \u5185\u5b58)\uff0c\u4e3a\u540e\u7eed\u5feb\u901f\u5206\u6790\u505a\u51c6\u5907\ndf.cache()\n\nprint(\"== Cell 1: \u6570\u636e\u52a0\u8f7d\u5b8c\u6210\u5e76\u5df2\u7f13\u5b58 ==\")"}, {"cell_type": "code", "execution_count": 4, "id": "000ab3ba-0df8-4891-b0cb-e47ae004589b", "metadata": {"tags": []}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "== Cell 2: \u63a2\u7d22\u539f\u59cb\u6570\u636e ==\nroot\n |-- STATION: string (nullable = true)\n |-- DATE: timestamp (nullable = true)\n |-- SOURCE: string (nullable = true)\n |-- LATITUDE: double (nullable = true)\n |-- LONGITUDE: double (nullable = true)\n |-- ELEVATION: double (nullable = true)\n |-- NAME: string (nullable = true)\n |-- REPORT_TYPE: string (nullable = true)\n |-- CALL_SIGN: string (nullable = true)\n |-- QUALITY_CONTROL: string (nullable = true)\n |-- WND: string (nullable = true)\n |-- CIG: string (nullable = true)\n |-- VIS: string (nullable = true)\n |-- TMP: string (nullable = true)\n |-- DEW: string (nullable = true)\n |-- SLP: string (nullable = true)\n |-- AA1: string (nullable = true)\n |-- AT1: string (nullable = true)\n |-- AT2: string (nullable = true)\n |-- AT3: string (nullable = true)\n |-- AT4: string (nullable = true)\n |-- AT5: string (nullable = true)\n |-- AT6: string (nullable = true)\n |-- AU1: string (nullable = true)\n |-- AU2: string (nullable = true)\n |-- AW1: string (nullable = true)\n |-- AW2: string (nullable = true)\n |-- GA1: string (nullable = true)\n |-- GA2: string (nullable = true)\n |-- GA3: string (nullable = true)\n |-- GD1: string (nullable = true)\n |-- GD2: string (nullable = true)\n |-- GD3: string (nullable = true)\n |-- MA1: string (nullable = true)\n |-- MW1: string (nullable = true)\n |-- OC1: string (nullable = true)\n |-- REM: string (nullable = true)\n |-- EQD: string (nullable = true)\n\n"}, {"name": "stderr", "output_type": "stream", "text": "[Stage 4:==>            (162 + 7) / 827][Stage 8:>                  (0 + 1) / 1]\r"}, {"name": "stdout", "output_type": "stream", "text": "+-------+-------+\n|TMP    |DEW    |\n+-------+-------+\n|+0008,5|-0022,5|\n|+0007,5|-0022,5|\n|+0006,5|-0022,5|\n|+0004,5|-0022,5|\n|+0004,5|-0023,5|\n|+0002,5|-0028,5|\n|+0000,5|-0029,5|\n|-0001,5|-0029,5|\n|-0001,5|-0029,5|\n|-0001,5|-0030,5|\n+-------+-------+\nonly showing top 10 rows\n\n"}, {"name": "stderr", "output_type": "stream", "text": "[Stage 4:===========>                                           (169 + 8) / 827]\r"}], "source": "print(\"== Cell 2: \u63a2\u7d22\u539f\u59cb\u6570\u636e ==\")\n\n# 1. \u67e5\u770b\u6570\u636e\u7c7b\u578b\n# \u4f60\u4f1a\u770b\u5230 TMP, DEW \u90fd\u662f string (\u5b57\u7b26\u4e32)\ndf.printSchema()\n\n# 2. \u67e5\u770b\u5185\u5bb9 (truncate=False \u663e\u793a\u5b8c\u6574\u5b57\u7b26\u4e32)\ndf.select(\"TMP\", \"DEW\").show(10, truncate=False)"}, {"cell_type": "code", "execution_count": 5, "id": "86156f2d-e87a-4826-a3ad-e4f12ae4106c", "metadata": {"tags": []}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "== Cell 3: \u6b63\u5728\u6e05\u7406\u6570\u636e ==\n== Cell 3: \u6e05\u7406\u7ed3\u679c\u5bf9\u6bd4 ==\n+-------+---------+-------+---------+\n|TMP    |TMP_clean|DEW    |DEW_clean|\n+-------+---------+-------+---------+\n|+0008,5|0.8      |-0022,5|-2.2     |\n|+0007,5|0.7      |-0022,5|-2.2     |\n|+0006,5|0.6      |-0022,5|-2.2     |\n|+0004,5|0.4      |-0022,5|-2.2     |\n|+0004,5|0.4      |-0023,5|-2.3     |\n|+0002,5|0.2      |-0028,5|-2.8     |\n|+0000,5|0.0      |-0029,5|-2.9     |\n|-0001,5|-0.1     |-0029,5|-2.9     |\n|-0001,5|-0.1     |-0029,5|-2.9     |\n|-0001,5|-0.1     |-0030,5|-3.0     |\n+-------+---------+-------+---------+\nonly showing top 10 rows\n\n"}, {"name": "stderr", "output_type": "stream", "text": "[Stage 4:===========>                                           (173 + 8) / 827]\r"}], "source": "print(\"== Cell 3: \u6b63\u5728\u6e05\u7406\u6570\u636e ==\")\n\ndef clean_column(df, col_name):\n    # \u6309\u9017\u53f7\u62c6\u5206 \"Value,Flag\"\n    split_col = F.split(df[col_name], ',')\n    \n    # \u63d0\u53d6 \"Value\" (+0100)\uff0c\u5e76\u8f6c\u4e3a\u6d6e\u70b9\u6570\n    value_col = split_col.getItem(0).cast('float')\n    \n    # \u6309\u6587\u6863\u8fc7\u6ee4\uff1a\u5982\u679c\u503c\u4e0d\u662f 9999\uff0c\u5c31\u9664\u4ee5 10\uff1b\u5426\u5219\u8bbe\u4e3a null (\u7a7a\u503c)\n    filtered_col = F.when(value_col != 9999, value_col / 10.0).otherwise(None)\n    \n    # \u8fd4\u56de\u4e00\u4e2a\u5e26\u65b0\u5217 (col_name_clean) \u7684 DataFrame\n    return df.withColumn(f\"{col_name}_clean\", filtered_col)\n\n# \u5e94\u7528\u6e05\u7406\ncleaned_df = clean_column(df, 'TMP')\ncleaned_df = clean_column(cleaned_df, 'DEW') # DEW (\u9732\u70b9) \u662f\u6211\u4eec\u7684\u7b2c\u4e00\u4e2a\u7279\u5f81\n\n# \u9a8c\u8bc1\u6e05\u7406\u7ed3\u679c\nprint(\"== Cell 3: \u6e05\u7406\u7ed3\u679c\u5bf9\u6bd4 ==\")\ncleaned_df.select(\"TMP\", \"TMP_clean\", \"DEW\", \"DEW_clean\").show(10, truncate=False)"}, {"cell_type": "code", "execution_count": 6, "id": "e2464bcb-5c77-4ddc-84ad-1bcb6ae9edbd", "metadata": {"tags": []}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "== Cell 4: \u51c6\u5907\u7528\u4e8e ML \u7684 DataFrame ==\n"}, {"name": "stderr", "output_type": "stream", "text": "[Stage 4:===>           (176 + 7) / 827][Stage 10:>                 (0 + 1) / 1]\r"}, {"name": "stdout", "output_type": "stream", "text": "+-----+---------+\n|label|DEW_clean|\n+-----+---------+\n|  0.8|     -2.2|\n|  0.7|     -2.2|\n|  0.6|     -2.2|\n|  0.4|     -2.2|\n|  0.4|     -2.3|\n|  0.2|     -2.8|\n|  0.0|     -2.9|\n| -0.1|     -2.9|\n| -0.1|     -2.9|\n| -0.1|     -3.0|\n+-----+---------+\nonly showing top 10 rows\n\n"}, {"name": "stderr", "output_type": "stream", "text": "[Stage 4:===========>                                           (178 + 8) / 827]\r"}], "source": "from pyspark.ml import Pipeline\nfrom pyspark.ml.feature import VectorAssembler, StandardScaler\n\nprint(\"== Cell 4: \u51c6\u5907\u7528\u4e8e ML \u7684 DataFrame ==\")\n\n# 1. \u9009\u62e9\u6211\u4eec\u8981\u7684\u5217\n# .alias(\"label\") \u662f MLlib \u7684\u6807\u51c6\u8981\u6c42\nmodel_df = cleaned_df.select(\n    F.col(\"TMP_clean\").alias(\"label\"),\n    F.col(\"DEW_clean\")  # \u8fd9\u662f\u6211\u4eec\u9009\u62e9\u7684\u7b2c\u4e00\u4e2a\u7279\u5f81\n).dropna() # \u4e22\u5f03\u4efb\u4f55\u6709 null \u503c\u7684\u884c\n\n# 2. \u67e5\u770b\u51c6\u5907\u597d\u7684\u6570\u636e\nmodel_df.show(10)"}, {"cell_type": "code", "execution_count": 7, "id": "ca429b8a-69a2-42c5-b62c-4d4be9c3f0f8", "metadata": {"tags": []}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "== Cell 5: \u5b9a\u4e49 Pipeline \u9636\u6bb5\u5e76\u62c6\u5206\u6570\u636e ==\n"}, {"name": "stderr", "output_type": "stream", "text": "[Stage 4:===>           (188 + 8) / 827][Stage 16:>                 (0 + 0) / 1]\r"}, {"name": "stdout", "output_type": "stream", "text": "== Cell 5: \u62c6\u5206\u5b8c\u6bd5\uff0c\u8bad\u7ec3\u96c6: 16956 \u884c, \u6d4b\u8bd5\u96c6: 7120 \u884c ==\n"}, {"name": "stderr", "output_type": "stream", "text": "[Stage 4:============>                                          (195 + 8) / 827]\r"}], "source": "print(\"== Cell 5: \u5b9a\u4e49 Pipeline \u9636\u6bb5\u5e76\u62c6\u5206\u6570\u636e ==\")\n\n# \u6b65\u9aa4 1: \u7279\u5f81\u6253\u5305\n# \u628a\u6240\u6709\u7279\u5f81\u5217\uff08\u76ee\u524d\u53ea\u6709 DEW_clean\uff09\u6253\u5305\u6210\u4e00\u4e2a\u5411\u91cf\nassembler = VectorAssembler(\n    inputCols=[\"DEW_clean\"], \n    outputCol=\"unscaled_features\"\n)\n\n# \u6b65\u9aa4 2: \u6807\u51c6\u5316\n# \u6309\u9879\u76ee\u8981\u6c42 (\"standardizing the data\") [cite: 902]\nscaler = StandardScaler(\n    inputCol=\"unscaled_features\", \n    outputCol=\"features\"\n)\n\n# \u6b65\u9aa4 3: \u62c6\u5206\u6570\u636e (70% \u8bad\u7ec3, 30% \u6d4b\u8bd5) \n(trainingData, testData) = model_df.randomSplit([0.7, 0.3], seed=42)\n\nprint(f\"== Cell 5: \u62c6\u5206\u5b8c\u6bd5\uff0c\u8bad\u7ec3\u96c6: {trainingData.count()} \u884c, \u6d4b\u8bd5\u96c6: {testData.count()} \u884c ==\")"}, {"cell_type": "code", "execution_count": 8, "id": "bf5e9258-cd2a-42ca-801d-58e3f3354707", "metadata": {"tags": []}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "== Cell 6: \u8bad\u7ec3\u6a21\u578b 1 (LinearRegression) ==\n"}, {"name": "stderr", "output_type": "stream", "text": "25/10/24 09:17:49 WARN Instrumentation: [8facddaa] regParam is zero, which might cause numerical instability and overfitting.\n[Stage 4:===>           (212 + 8) / 827][Stage 22:============>     (2 + 0) / 3]\r"}, {"name": "stdout", "output_type": "stream", "text": "==============================\n\u6a21\u578b 1 (LinearRegression) \u7684 RMSE: 5.489006811081679\n==============================\n"}, {"name": "stderr", "output_type": "stream", "text": "[Stage 4:=================>                                     (268 + 8) / 827]\r"}], "source": "from pyspark.ml.regression import LinearRegression\nfrom pyspark.ml.evaluation import RegressionEvaluator\n\nprint(\"== Cell 6: \u8bad\u7ec3\u6a21\u578b 1 (LinearRegression) ==\")\n\n# 1. \u5b9a\u4e49\u6a21\u578b\nlr = LinearRegression(featuresCol=\"features\", labelCol=\"label\")\n\n# 2. \u7ec4\u88c5\u6700\u7ec8 Pipeline\npipeline_lr = Pipeline(stages=[assembler, scaler, lr])\n\n# 3. \u8bad\u7ec3\nmodel_lr = pipeline_lr.fit(trainingData)\n\n# 4. \u9884\u6d4b\npredictions_lr = model_lr.transform(testData)\n\n# 5. \u8bc4\u4f30 (RMSE) \nevaluator = RegressionEvaluator(\n    labelCol=\"label\", \n    predictionCol=\"prediction\", \n    metricName=\"rmse\"\n)\nrmse_lr = evaluator.evaluate(predictions_lr)\n\nprint(\"=\"*30)\nprint(f\"\u6a21\u578b 1 (LinearRegression) \u7684 RMSE: {rmse_lr}\")\nprint(\"=\"*30)"}, {"cell_type": "code", "execution_count": 9, "id": "80a404e0-c1e8-41a0-9ec0-3d644f899242", "metadata": {"tags": []}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "== Cell 7: \u8bad\u7ec3\u6a21\u578b 2 (DecisionTreeRegressor) ==\n"}, {"name": "stderr", "output_type": "stream", "text": "[Stage 4:=====>         (317 + 7) / 827][Stage 40:============>     (2 + 1) / 3]\r"}, {"name": "stdout", "output_type": "stream", "text": "==============================\n\u6a21\u578b 2 (DecisionTreeRegressor) \u7684 RMSE: 5.549243089672489\n==============================\n== \u6846\u67b6\u642d\u5efa\u5b8c\u6bd5\uff01 ==\n"}, {"name": "stderr", "output_type": "stream", "text": "[Stage 4:=====================================>                 (559 + 8) / 827]\r"}], "source": "from pyspark.ml.regression import DecisionTreeRegressor\n\nprint(\"== Cell 7: \u8bad\u7ec3\u6a21\u578b 2 (DecisionTreeRegressor) ==\")\n\n# 1. \u5b9a\u4e49\u65b0\u6a21\u578b\ndt = DecisionTreeRegressor(featuresCol=\"features\", labelCol=\"label\")\n\n# 2. \u7ec4\u88c5\u65b0 Pipeline (\u6ce8\u610f\u6211\u4eec\u6362\u6389\u4e86 lr)\npipeline_dt = Pipeline(stages=[assembler, scaler, dt])\n\n# 3. \u8bad\u7ec3\nmodel_dt = pipeline_dt.fit(trainingData)\n\n# 4. \u9884\u6d4b\npredictions_dt = model_dt.transform(testData)\n\n# 5. \u8bc4\u4f30 (\u4f7f\u7528 Cell 6 \u5b9a\u4e49\u7684\u540c\u4e00\u4e2a evaluator)\nrmse_dt = evaluator.evaluate(predictions_dt)\n\nprint(\"=\"*30)\nprint(f\"\u6a21\u578b 2 (DecisionTreeRegressor) \u7684 RMSE: {rmse_dt}\")\nprint(\"=\"*30)\nprint(\"== \u6846\u67b6\u642d\u5efa\u5b8c\u6bd5\uff01 ==\")"}, {"cell_type": "code", "execution_count": null, "id": "92577553-63ee-4419-84ee-84ea63ea9765", "metadata": {}, "outputs": [], "source": ""}], "metadata": {"kernelspec": {"display_name": "PySpark", "language": "python", "name": "pyspark"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.11.8"}}, "nbformat": 4, "nbformat_minor": 5}